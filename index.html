<!DOCTYPE html>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<body
  style="
    margin: 0;
    background: #000;
    display: grid;
    place-items: center;
    height: 100dvh;
    overflow: hidden;
  "
>
  <!-- Keep the video decoding: do NOT display:none -->
  <video
    id="src"
    playsinline
    muted
    autoplay
    style="
      position: fixed;
      left: -9999px;
      top: -9999px;
      width: 1px;
      height: 1px;
      opacity: 0;
      pointer-events: none;
    "
  ></video>

  <canvas
    id="out"
    style="width: 100vw; height: 100vh; object-fit: cover"
  ></canvas>

  <!-- Controls -->
  <div
    id="controls"
    style="
      position: fixed;
      left: 0;
      right: 0;
      bottom: 0;
      padding: 12px 16px;
      background: rgba(0, 0, 0, 0.45);
      backdrop-filter: blur(6px);
      color: #fff;
      font: 500 16px system-ui, -apple-system, Segoe UI, Roboto;
    "
  >
    <label style="display: block; margin: 0 0 6px">
      Lag rate (playback speed): <span id="rateVal">0.50×</span>
    </label>
    <input
      id="rate"
      type="range"
      min="0.20"
      max="1.00"
      step="0.05"
      value="0.50"
      style="width: 100%"
    />
  </div>

  <!-- Only shown if auto-start fails and a user gesture is required -->
  <div
    id="tapToStart"
    style="
      display: none;
      position: fixed;
      inset: 0;
      display: grid;
      place-items: center;
      background: rgba(0, 0, 0, 0.6);
      color: #fff;
      text-align: center;
      padding: 24px;
      font: 600 18px system-ui, -apple-system, Segoe UI, Roboto;
      user-select: none;
    "
  >
    <div>
      <div style="font-size: 20px; margin-bottom: 8px">
        Tap to enable camera
      </div>
      <div style="opacity: 0.8">
        Browser blocked auto-start. One tap will grant permission.
      </div>
    </div>
  </div>

  <script>
    /*** Rear camera selection (unchanged logic) ***/
    async function getRearStream() {
      const base = { width: { ideal: 1920 }, height: { ideal: 1080 } };
      const gum = (extra = {}) =>
        navigator.mediaDevices.getUserMedia({
          video: { ...base, ...extra },
          audio: false,
        });

      try {
        return await gum({ facingMode: { exact: "environment" } });
      } catch {}
      try {
        return await gum({ facingMode: { ideal: "environment" } });
      } catch {}

      // Enumerate as fallback (needs prior permission on most phones)
      let tempStream = null;
      try {
        tempStream = await gum({ facingMode: { ideal: "user" } });
      } catch {}
      let devices = [];
      try {
        devices = await navigator.mediaDevices.enumerateDevices();
      } finally {
        if (tempStream) tempStream.getTracks().forEach((t) => t.stop());
      }

      const cams = devices.filter((d) => d.kind === "videoinput");
      const rearish = cams.find((d) => /back|rear|environment/i.test(d.label));
      if (rearish) {
        return await navigator.mediaDevices.getUserMedia({
          video: { deviceId: { exact: rearish.deviceId }, ...base },
          audio: false,
        });
      }
      if (cams.length > 1) {
        return await navigator.mediaDevices.getUserMedia({
          video: {
            deviceId: { exact: cams[cams.length - 1].deviceId },
            ...base,
          },
          audio: false,
        });
      }
      return await gum();
    }

    /*** App ***/
    const src = document.getElementById("src");
    const canvas = document.getElementById("out");
    const ctx = canvas.getContext("2d", { alpha: false });

    // We downscale capture before buffering to reduce memory.
    // 1.0 = native, 0.75 = 75% each dimension (~56% pixels), 0.5 = quarter pixels.
    const CAPTURE_SCALE = 0.75;

    // Keep capture cadence reasonable; too fast = memory spikes.
    const TARGET_CAPTURE_FPS = 24;

    // If createImageBitmap is flaky, we shrink buffer to be extra safe.
    const supportsRVFC =
      "requestVideoFrameCallback" in HTMLVideoElement.prototype;
    const supportsCreateImageBitmap = "createImageBitmap" in window;

    // Buffer sizing
    let measuredFps = TARGET_CAPTURE_FPS;
    let MAX_BUFFER_SECONDS = 8; // normal
    if (!supportsCreateImageBitmap) MAX_BUFFER_SECONDS = 3; // conservative fallback
    let MAX_FRAMES = Math.max(
      8,
      Math.floor(MAX_BUFFER_SECONDS * TARGET_CAPTURE_FPS)
    );

    // State
    let running = false;
    let slowFactor = 0.5; // controlled by slider
    let inFlight = 0; // imageBitmap conversions currently in flight
    let lastCaptureMs = 0;
    let lastDrawn = null; // last frame to hold on underrun

    // UI wiring
    const rate = document.getElementById("rate");
    const rateVal = document.getElementById("rateVal");
    rate.addEventListener("input", (e) => {
      slowFactor = Number(e.target.value);
      rateVal.textContent = slowFactor.toFixed(2) + "×";
    });

    const buf = document.createElement("canvas");
    const bctx = buf.getContext("2d", { alpha: false });

    // Ring buffer
    const frameQueue = [];
    function clearQueue() {
      while (frameQueue.length) {
        const f = frameQueue.shift();
        if (f && f.close)
          try {
            f.close();
          } catch {}
      }
    }

    function pushFrame(frame) {
      if (!running) {
        if (frame && frame.close) frame.close();
        return;
      }
      if (frameQueue.length >= MAX_FRAMES) {
        const old = frameQueue.shift();
        if (old && old.close)
          try {
            old.close();
          } catch {}
      }
      frameQueue.push(frame);
    }

    // Capture one frame with throttling + downscale
    function captureOnce(nowMs) {
      if (!running || !src.videoWidth || !src.videoHeight) return;

      const minInterval = 1000 / TARGET_CAPTURE_FPS;
      if (nowMs - lastCaptureMs < minInterval) return; // throttle capture
      if (inFlight >= 1) return; // backpressure: only 1 in-flight
      if (frameQueue.length >= MAX_FRAMES - 1) return; // buffer nearly full → skip

      lastCaptureMs = nowMs;
      const w = Math.max(2, Math.floor(src.videoWidth * CAPTURE_SCALE));
      const h = Math.max(2, Math.floor(src.videoHeight * CAPTURE_SCALE));
      if (buf.width !== w || buf.height !== h) {
        buf.width = w;
        buf.height = h;
      }
      try {
        bctx.drawImage(src, 0, 0, w, h);
      } catch {
        return;
      }

      inFlight++;
      if (supportsCreateImageBitmap) {
        createImageBitmap(buf)
          .then((bmp) => {
            inFlight--;
            pushFrame(bmp);
          })
          .catch(() => {
            inFlight--;
            // As a last resort, drop this frame.
          });
      } else {
        // Very conservative fallback: clone into a single pooled canvas object
        // (avoid creating many canvases per second)
        const c = document.createElement("canvas");
        c.width = w;
        c.height = h;
        try {
          c.getContext("2d", { alpha: false }).drawImage(buf, 0, 0);
        } catch {}
        inFlight--;
        pushFrame(c);
      }
    }

    // Producer loop
    function scheduleProducer() {
      if (!running) return;
      if (supportsRVFC) {
        src.requestVideoFrameCallback((_, meta) => {
          if (!running) return;
          if (meta && meta.mediaTime && meta.presentedFrames) {
            const est = meta.presentedFrames / meta.mediaTime;
            if (isFinite(est) && est > 0)
              measuredFps = Math.max(12, Math.min(60, est));
            // Keep buffer cap consistent with measured fps
            MAX_FRAMES = Math.max(
              8,
              Math.floor(
                MAX_BUFFER_SECONDS * Math.min(measuredFps, TARGET_CAPTURE_FPS)
              )
            );
          }
          captureOnce(performance.now());
          scheduleProducer();
        });
      } else {
        // Timer-based producer
        setTimeout(() => {
          captureOnce(performance.now());
          scheduleProducer();
        }, Math.max(10, Math.floor(1000 / TARGET_CAPTURE_FPS)));
      }
    }

    // Consumer loop
    function drawLoop() {
      if (!running) return;
      let frame = frameQueue.shift();
      if (frame) lastDrawn = frame;
      else frame = lastDrawn;

      if (frame) {
        const w = frame.width || buf.width;
        const h = frame.height || buf.height;
        if (canvas.width !== w || canvas.height !== h) {
          canvas.width = w;
          canvas.height = h;
        }
        try {
          ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);
        } catch {}
        if (frame !== lastDrawn && frame.close) {
          // don't close the held frame
          try {
            frame.close();
          } catch {}
        }
      }
      // Playback speed control. Clamp to avoid 0ms timers.
      const playbackFps = Math.max(
        6,
        Math.min(60, (measuredFps || TARGET_CAPTURE_FPS) * slowFactor)
      );
      setTimeout(drawLoop, Math.max(10, Math.floor(1000 / playbackFps)));
    }

    async function startCamera() {
      try {
        const stream = await getRearStream();
        src.srcObject = stream;
        await src.play();
        running = true;
        scheduleProducer();
        drawLoop();
        const overlay = document.getElementById("tapToStart");
        if (overlay) overlay.style.display = "none";
      } catch (e) {
        console.error(e);
        // If auto-start is blocked, show a one-tap overlay to satisfy user gesture.
        const overlay = document.getElementById("tapToStart");
        if (overlay) {
          overlay.style.display = "grid";
          overlay.onclick = async () => {
            overlay.textContent = "Requesting camera…";
            try {
              await startCamera();
            } catch (err) {
              alert(
                "Camera failed. Ensure HTTPS and allow camera.\n\n" +
                  err.message
              );
              overlay.textContent = "Tap to enable camera";
            }
          };
        } else {
          alert(
            "Camera failed. Ensure HTTPS and allow camera.\n\n" + e.message
          );
        }
      }
    }

    // Auto-start; overlay appears only if the browser demands a gesture.
    window.addEventListener("load", startCamera);

    // Pause/resume logic
    document.addEventListener("visibilitychange", () => {
      if (document.hidden) {
        running = false;
      } else {
        if (!running) {
          running = true;
          scheduleProducer();
          drawLoop();
        }
      }
    });

    // Clean up on unload (frees camera + memory)
    window.addEventListener("beforeunload", () => {
      try {
        const s = src.srcObject;
        if (s) s.getTracks().forEach((t) => t.stop());
      } catch {}
      clearQueue();
      running = false;
    });
  </script>
</body>
