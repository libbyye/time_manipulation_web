<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, viewport-fit=cover"
    />
    <title>iPhone Camera Buffer Demo</title>
    <style>
      :root {
        --bg: #0b0c0f; /* near-black */
        --fg: #e8eef6; /* high-contrast text */
        --muted: #9fb0c3;
        --accent: #4aa8ff;
        --accent-2: #00d3a7;
      }
      html,
      body {
        height: 100%;
        margin: 0;
        background: var(--bg);
        color: var(--fg);
        -webkit-text-size-adjust: 100%;
      }
      body {
        display: grid;
        grid-template-rows: auto 1fr auto;
        gap: 0.5rem;
        font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica,
          Arial, sans-serif;
      }
      header {
        position: sticky;
        top: 0;
        z-index: 10;
        background: linear-gradient(
          to bottom,
          rgba(11, 12, 15, 0.97),
          rgba(11, 12, 15, 0.5)
        );
        backdrop-filter: blur(8px);
        -webkit-backdrop-filter: blur(8px);
        padding: env(safe-area-inset-top) 12px 8px 12px;
        border-bottom: 1px solid rgba(255, 255, 255, 0.08);
      }
      .controls {
        display: grid;
        grid-template-columns: 1fr auto;
        gap: 0.75rem 0.75rem;
        align-items: center;
      }
      @media (min-width: 700px) {
        .controls {
          grid-template-columns: auto 1fr auto auto;
        }
      }
      label {
        font-weight: 600;
      }
      .row {
        display: contents;
      }
      .range-wrap {
        display: grid;
        gap: 0.25rem;
      }
      input[type="range"] {
        width: 100%;
      }
      button {
        appearance: none;
        -webkit-appearance: none;
        border: 0;
        border-radius: 14px;
        padding: 0.8rem 1rem;
        font-weight: 700;
        color: #04131c;
        background: var(--accent);
        box-shadow: 0 1px 0 rgba(255, 255, 255, 0.25) inset,
          0 8px 16px rgba(0, 0, 0, 0.25);
      }
      button[disabled] {
        opacity: 0.6;
      }
      .ghost {
        background: transparent;
        color: var(--fg);
        border: 1px solid rgba(255, 255, 255, 0.22);
      }
      .status {
        color: var(--muted);
        font-size: 0.95rem;
      }

      main {
        position: relative;
      }
      .stage {
        position: relative;
        width: 100vw;
        height: calc(100vh - 170px);
        max-height: 70svh;
        display: grid;
        place-items: center;
        background: #000;
        border-radius: 16px;
        overflow: hidden;
        margin: 0 12px;
        border: 1px solid rgba(255, 255, 255, 0.08);
      }
      canvas {
        width: 100%;
        height: 100%;
        display: block;
      }

      .overlay {
        position: absolute;
        inset: 0;
        pointer-events: none;
        display: grid;
        place-items: center;
        text-align: center;
        padding: 1rem;
        color: var(--muted);
        background: radial-gradient(
          1200px 600px at 50% 50%,
          rgba(0, 0, 0, 0),
          rgba(0, 0, 0, 0.45)
        );
        font-weight: 600;
        letter-spacing: 0.02em;
      }
      .pill {
        position: absolute;
        right: 12px;
        bottom: 12px;
        border-radius: 999px;
        background: rgba(0, 0, 0, 0.55);
        padding: 0.35rem 0.6rem;
        font-size: 0.85rem;
        color: var(--fg);
        border: 1px solid rgba(255, 255, 255, 0.14);
      }
      footer {
        padding: 0.75rem 12px calc(10px + env(safe-area-inset-bottom));
      }
      .hint {
        color: var(--muted);
        font-size: 0.85rem;
      }

      /* Improve tap targets and disable double-tap zoom for controls */
      * {
        touch-action: manipulation;
      }
      input[type="range"] {
        height: 36px;
      }

      @media (prefers-reduced-motion: reduce) {
        .overlay {
          background: rgba(0, 0, 0, 0.4);
        }
      }
    </style>
  </head>
  <body>
    <header>
      <div class="controls" role="group" aria-label="Camera controls">
        <div class="row">
          <label for="rate">Speed</label>
          <div class="range-wrap">
            <input
              id="rate"
              type="range"
              min="0.30"
              max="1.00"
              step="0.01"
              value="1.00"
              aria-valuemin="0.30"
              aria-valuemax="1.00"
              aria-valuenow="1.00"
              aria-label="Playback speed"
            />
            <output id="rateOut" for="rate" aria-live="polite"
              >1.00× (near‑live)</output
            >
          </div>
        </div>
        <div class="row" style="justify-self: end; display: flex; gap: 0.5rem">
          <button
            id="start"
            type="button"
            aria-controls="view"
            aria-label="Start camera"
          >
            Start Camera
          </button>
          <button
            id="resetLatency"
            type="button"
            class="ghost"
            aria-label="Reset latency to live"
            title="Clear the buffer and jump to live"
            disabled
          >
            Jump to Live
          </button>
        </div>
      </div>
      <div class="status" role="status" aria-live="polite" id="status">
        Not started. Tap “Start Camera” to grant permission.
      </div>
    </header>

    <main>
      <div class="stage" id="stage">
        <canvas id="view" aria-label="Camera view" role="img"></canvas>
        <div class="overlay" id="overlay">Waiting for camera…</div>
        <div class="pill" id="pill">LIVE</div>
      </div>
      <!-- Hidden video source (required by getUserMedia); must be user-gesture started on iOS -->
      <video
        id="src"
        playsinline
        muted
        style="
          position: absolute;
          left: -9999px;
          top: -9999px;
          width: 1px;
          height: 1px;
        "
      ></video>
    </main>

    <script>
      (() => {
        const els = {
          start: document.getElementById("start"),
          resetLatency: document.getElementById("resetLatency"),
          rate: document.getElementById("rate"),
          rateOut: document.getElementById("rateOut"),
          status: document.getElementById("status"),
          overlay: document.getElementById("overlay"),
          pill: document.getElementById("pill"),
          video: document.getElementById("src"),
          canvas: document.getElementById("view"),
          stage: document.getElementById("stage"),
        };

        const ctx = els.canvas.getContext("2d", {
          alpha: false,
          desynchronized: true,
        });

        /*** State ***/
        let stream = null;
        let running = false;
        let playbackRate = 1.0; // 1.0 = live; <1.0 = buffered slow-mo
        let mode = "live";

        // Frame timing estimation for source FPS
        let lastCaptureTS = 0;
        let fpsEstimate = 30; // EMA starts at 30

        // Buffered frames (array of canvases or offscreen canvases)
        let buffer = [];
        let lastDrawnFrame = null; // store the last frame source for redraw when paused
        let displayIntervalMs = 1000 / fpsEstimate; // will be adjusted by rate
        let lastDisplayAt = 0;

        // Limits
        const MAX_BUFFER_SECONDS = 6; // soft cap
        let MAX_FRAMES = Math.round(MAX_BUFFER_SECONDS * fpsEstimate);

        // Helpers
        const fmt2 = (n) => Number(n).toFixed(2);

        function logStatus(text) {
          els.status.textContent = text;
        }

        function updatePill() {
          if (playbackRate >= 0.999) {
            els.pill.textContent = "LIVE";
            els.pill.style.background = "rgba(0,0,0,.55)";
            els.pill.style.borderColor = "rgba(255,255,255,.14)";
          } else {
            els.pill.textContent = fmt2(playbackRate) + "×";
            els.pill.style.background = "rgba(0, 138, 92, .55)";
            els.pill.style.borderColor = "rgba(0, 255, 190, .25)";
          }
        }

        function setOverlay(text = "") {
          els.overlay.textContent = text;
          els.overlay.style.opacity = text ? "1" : "0";
        }

        function resizeCanvasToVideo() {
          const v = els.video;
          const ratio =
            v.videoWidth && v.videoHeight
              ? v.videoWidth / v.videoHeight
              : 16 / 9;
          const rect = els.stage.getBoundingClientRect();
          // Fit the canvas within stage while preserving aspect
          let w = rect.width,
            h = rect.height;
          if (w / h > ratio) {
            w = Math.round(h * ratio);
          } else {
            h = Math.round(w / ratio);
          }
          els.canvas.width = w;
          els.canvas.height = h;
        }

        function estimateFPS(now) {
          if (lastCaptureTS) {
            const dt = now - lastCaptureTS;
            const inst = dt > 0 ? 1000 / dt : fpsEstimate;
            // exponential moving average for stability
            fpsEstimate = fpsEstimate * 0.9 + inst * 0.1;
            MAX_FRAMES = Math.max(
              10,
              Math.round(MAX_BUFFER_SECONDS * fpsEstimate)
            );
            displayIntervalMs =
              1000 / fpsEstimate / Math.max(0.001, playbackRate);
          }
          lastCaptureTS = now;
        }

        function approxLatencySec() {
          if (playbackRate >= 0.999) return 0;
          const frames = buffer.length;
          const fps = Math.max(1, fpsEstimate);
          return frames / fps;
        }

        // Capture loop: grabs frames as they come. We only store when in buffered mode.
        function captureFrame() {
          const now = performance.now();
          estimateFPS(now);

          if (mode === "buffered") {
            // Choose a compact buffer resolution to manage memory
            const bw = Math.min(els.canvas.width, 640);
            const bh = Math.round(
              bw * (els.video.videoHeight / Math.max(1, els.video.videoWidth))
            );
            const frameCanvas =
              "OffscreenCanvas" in window
                ? new OffscreenCanvas(bw, bh)
                : Object.assign(document.createElement("canvas"), {
                    width: bw,
                    height: bh,
                  });
            frameCanvas.width = bw;
            frameCanvas.height = bh;
            const bctx = frameCanvas.getContext("2d");
            bctx.drawImage(els.video, 0, 0, bw, bh);

            buffer.push({ source: frameCanvas, t: now });
            // Trim if exceeding max frames
            if (buffer.length > MAX_FRAMES)
              buffer.splice(0, buffer.length - MAX_FRAMES);
          }
        }

        // Render loop: draws to display canvas
        function render(now) {
          if (!running) return;

          if (mode === "live") {
            // Draw the most recent frame directly from video
            ctx.drawImage(els.video, 0, 0, els.canvas.width, els.canvas.height);
            lastDrawnFrame = null;
          } else {
            // Buffered slow playback
            const needNewFrame = now - lastDisplayAt >= displayIntervalMs;
            if (needNewFrame && buffer.length > 0) {
              lastDrawnFrame = buffer.shift();
              lastDisplayAt = now;
            }

            if (lastDrawnFrame) {
              ctx.drawImage(
                lastDrawnFrame.source,
                0,
                0,
                els.canvas.width,
                els.canvas.height
              );
            } else {
              // No frames yet — show a subtle message
              ctx.fillStyle = "#000";
              ctx.fillRect(0, 0, els.canvas.width, els.canvas.height);
            }
          }

          // Update overlay & status
          const latency = approxLatencySec();
          if (mode === "buffered" && buffer.length === 0) {
            setOverlay("Buffering…");
          } else if (mode === "buffered") {
            setOverlay("");
          } else {
            setOverlay("");
          }

          requestAnimationFrame(render);
        }

        async function startCamera() {
          if (running) return;
          try {
            els.start.disabled = true;
            logStatus(
              "Requesting camera… (Use HTTPS; iOS requires a user gesture)"
            );
            const constraints = {
              audio: false,
              video: {
                facingMode: { ideal: "environment" },
                width: { ideal: 1280 },
                height: { ideal: 720 },
                frameRate: { ideal: 30 },
              },
            };

            stream = await navigator.mediaDevices.getUserMedia(constraints);
            els.video.srcObject = stream;

            await els.video.play(); // must be after a user gesture on iOS
            await new Promise((res) => {
              if (els.video.readyState >= 2) return res();
              els.video.onloadeddata = () => res();
            });

            resizeCanvasToVideo();
            window.addEventListener("resize", resizeCanvasToVideo);

            running = true;
            els.resetLatency.disabled = false;
            logStatus(
              "Camera started. Drag the slider: < 1.00× adds latency via buffering; 1.00× is near‑live."
            );
            setOverlay("");

            // Prefer requestVideoFrameCallback if available for capture pacing
            const hasRVFC =
              "requestVideoFrameCallback" in HTMLVideoElement.prototype;
            if (hasRVFC) {
              const pump = (now, meta) => {
                if (!running) return;
                captureFrame();
                els.video.requestVideoFrameCallback(pump);
              };
              els.video.requestVideoFrameCallback(pump);
            } else {
              // Fallback: use rAF to sample frames ~60Hz
              const pump = () => {
                if (!running) return;
                captureFrame();
                requestAnimationFrame(pump);
              };
              requestAnimationFrame(pump);
            }

            requestAnimationFrame(render);
          } catch (err) {
            console.error(err);
            els.start.disabled = false;
            logStatus(
              "Error: " + (err && err.message ? err.message : String(err))
            );
            setOverlay("Permission denied or camera unavailable");
          }
        }

        function setRate(v) {
          playbackRate = Math.max(0.3, Math.min(1.0, Number(v)));
          els.rate.value = String(playbackRate);
          els.rate.setAttribute("aria-valuenow", String(playbackRate));
          const label =
            playbackRate >= 0.999
              ? "1.00× (near‑live)"
              : `${fmt2(playbackRate)}× (buffered)`;
          els.rateOut.value = label; // for <output>
          els.rateOut.textContent = label;

          updatePill();

          if (playbackRate >= 0.999) {
            mode = "live";
            buffer.length = 0; // drop latency
            lastDrawnFrame = null;
            logStatus("Near‑live video (minimal delay).");
          } else {
            mode = "buffered";
            // Recompute display interval against most recent FPS estimate
            displayIntervalMs =
              1000 / Math.max(1, fpsEstimate) / Math.max(0.001, playbackRate);
          }
        }

        function jumpToLive() {
          buffer.length = 0;
          lastDrawnFrame = null;
          lastDisplayAt = 0;
          logStatus("Buffer cleared; jumped to live.");
        }

        // Wire up UI
        els.start.addEventListener("click", startCamera, { passive: true });
        els.resetLatency.addEventListener("click", jumpToLive, {
          passive: true,
        });

        els.rate.addEventListener("input", (e) => setRate(e.target.value), {
          passive: true,
        });
        els.rate.addEventListener("change", (e) => setRate(e.target.value), {
          passive: true,
        });

        // Init text
        setRate(1.0);
      })();
    </script>
  </body>
</html>
